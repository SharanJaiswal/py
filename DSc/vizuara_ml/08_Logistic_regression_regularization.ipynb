{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5871fc7",
   "metadata": {},
   "source": [
    "# No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "364c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f125449a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/ex2data2.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/ex2data2.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], data[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonlab/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1395\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1393\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1395\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonlab/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1022\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1024\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonlab/lib/python3.10/site-packages/numpy/lib/_datasource.py:192\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonlab/lib/python3.10/site-packages/numpy/lib/_datasource.py:529\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    527\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: data/ex2data2.txt not found."
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/ex2data2.txt', delimiter=',', dtype=np.float64)\n",
    "X, y = data[:, :-1], data[:, -1].reshape((-1, 1))   # In data, first 2 cols are coordinates, last col is label (0 or 1). Points are distributed in a circular manner, where inner clircle is labeled 0 and outer circle is labeled 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f113fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f12187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c531562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta, X, y):\n",
    "    h = sigmoid(np.dot(x, theta))\n",
    "    cos = -(np.sum(y * np.log(h)) + np.sum((1 - y) * np.log(1 - h))) / len(y)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9a28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    grad = np.dot(X.T, (h - y)) / len(y)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c02150",
   "metadata": {},
   "source": [
    "#### The Featurization Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a64eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_feature(x1, x2, power = 2):\n",
    "    # Expand a 2D feature matrix to polynomial features up to the power\n",
    "    new_X = np.ones((x1.shape[0], 1))   # Add a column of ones for bias term\n",
    "    for i in range(1, power + 1):\n",
    "        for j in range(i + 1):\n",
    "            new_feature = (x1 ** (i - j)) * (x2 ** j)\n",
    "            new_X = np.hstack((new_X, new_feature.reshape((-1, 1))))    # np.append(new_X, (x1**(i-j)*(x2**j)).reshape((-1,1)), axis=1)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f3c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a more general version of the above function that can handle any number of features and expand them to a given degree.\n",
    "\n",
    "def expand_features(X, degree):\n",
    "    from itertools import combinations_with_replacement\n",
    "    n_samples, n_features = X.shape\n",
    "    combos = list(combinations_with_replacement(range(n_features), degree))\n",
    "    X_expanded = np.ones((n_samples, len(combos)))\n",
    "    for i, combo in enumerate(combos):\n",
    "        for index in combo:\n",
    "            X_expanded[:, i] *= X[:, index]\n",
    "    return X_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18aa9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    prob = sigmoid(np.dot(X, theta))\n",
    "    return (prob >= 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd7c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    for _ in range(num_iters):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        theta -= (alpha / m) * np.dot(X.T, (h - y))\n",
    "        costs.append(loss(theta, X, y))\n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb57054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Logistic Regression without Regularization\n",
    "def logistic_regression_no_reg(X, y, power=2, alpha=0.01, num_iters=100):   # 3 hyper params: Learning rate APLHA, num of iterations, power of polynomial features\n",
    "    X_expanded = expand_feature(X[:, 0], X[:, 1], power = power) # Expand features to given power\n",
    "    initial_theta = np.zeros((X_expanded.shape[1], 1))  # Initialize theta\n",
    "    theta, costs = gradient_descent(X_expanded, y, initial_theta, alpha, num_iters)\n",
    "    predicted = predict(theta, X_expanded)\n",
    "    accuracy = np.mean(predicted == y.flatten()) * 100\n",
    "    print(f'Accuracy without regularization: {accuracy:.2f}%')\n",
    "    return predicted, theta, costs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b226f42",
   "metadata": {},
   "source": [
    "#### Decide the polynomial power in the features, and the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71da04d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m power, num_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m predicted, theta, costs \u001b[38;5;241m=\u001b[39m logistic_regression_no_reg(\u001b[43mX\u001b[49m, y, power\u001b[38;5;241m=\u001b[39mpower, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, num_iters\u001b[38;5;241m=\u001b[39mnum_iters)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "power, num_iters, alpha = 20, 20000, 0.6\n",
    "predicted, theta, costs = logistic_regression_no_reg(X, y, power=power, alpha=alpha, num_iters=num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5c51e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTheaccuracy is \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.2f}\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39msum(\u001b[43mpredicted\u001b[49m \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "'Theaccuracy is {.2f}%'.format(np.sum(predicted == y.flatten()) / len(y) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911bc63",
   "metadata": {},
   "source": [
    "#### Visualize the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "007a5736",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(np\u001b[38;5;241m.\u001b[39mmin(\u001b[43mX\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(X[:, \u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(np\u001b[38;5;241m.\u001b[39mmin(X[:, \u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(X[:, \u001b[38;5;241m1\u001b[39m]), \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(u), \u001b[38;5;28mlen\u001b[39m(v)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "u = np.linspace(np.min(X[:, 0]), max(X[:, 0]), 50)\n",
    "v = np.linspace(np.min(X[:, 1]), max(X[:, 1]), 50)\n",
    "\n",
    "z = np.zeros((len(u), len(v)))\n",
    "\n",
    "for i in range(len(u)):\n",
    "    for j in range(len(v)):\n",
    "        features = expand_feature(np.array([u[i]]).reshape(1, -1), np.array([v[j]]).reshape(1, -1), power=power)\n",
    "        z[i, j] = np.dot(features, theta)\n",
    "z = z.T\n",
    "\n",
    "plt.contour(u,v,z, [0, 0.01], cmap = 'Reds')\n",
    "sns.scatterplot(x = X[:, 0], y = X[:, 1], hue = y.flatten())\n",
    "plt.title('Logistic Regression without Regularization Decision Boundary')\n",
    "plt.xlabel('Feature 1 aka X')\n",
    "plt.ylabel('Feature 2 aka Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e5a7b",
   "metadata": {},
   "source": [
    "This is an example of Overfitted model. Try changing the order hyperparam and see that model is not getting overfitted. This will also compute optimal model in less time with same accuracy, making unnecessary increase in compute time in manifolds, and that too giving over-fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a26c80",
   "metadata": {},
   "source": [
    "# With Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91dd27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_with_reg(theta, X, y, lambda_ = 0):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    theta1 = theta.copy()\n",
    "    theta1[0] = 0  # Exclude bias term from regularization\n",
    "    reg_term = (lambda_ / m) * np.sum(theta1 ** 2)  # Exclude bias term from regularization. ALSO, in another method, we divide by 2m instead of m. Since we are not using 2m, so we multiply by 2 in gradient calculation in grad_reg function below in the reg_term while calculating gradient.\n",
    "    cost = -(np.sum(y * np.log(h)) + np.sum((1 - y) * np.log(1 - h))) / m + reg_term\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a22d2f",
   "metadata": {},
   "source": [
    "#### Regularization: Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9077c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_reg(theta, X, y, lambda_ = 0):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    theta1 = theta.copy()\n",
    "    theta1[0] = 0  # Exclude bias term from regularization\n",
    "    reg_term = (lambda_ / m) * theta1\n",
    "    grad = (np.dot(X.T, (h - y)) / m) + (2 * reg_term)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1992c",
   "metadata": {},
   "source": [
    "#### Regularization: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2633cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg(X, y, theta, alpha, num_iters = 100, lambda_ = 0):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    for _ in range(num_iters):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        theta1 = theta.copy()\n",
    "        theta1[0] = 0  # Exclude(or, replacing) bias term from regularization\n",
    "        theta -= alpha * grad_reg(theta1, X, y, lambda_)\n",
    "        costs.append(cost_with_reg(theta1, X, y, lambda_))\n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1b468",
   "metadata": {},
   "source": [
    "#### Regularization: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_reg(X, y, power=2, alpha=0.01, num_iters=100, lambda_ = 0):   # 4 hyper params: Learning rate APLHA, num of iterations, power of polynomial features, regularization parameter lambda\n",
    "    X_expanded = expand_feature(X[:, 0], X[:, 1], power = power) # Expand features to given power\n",
    "    initial_theta = np.zeros((X_expanded.shape[1], 1), dtype = np.float64)  # Initialize theta\n",
    "    theta, costs = gradient_descent_reg(X_expanded, y, initial_theta, alpha, num_iters, lambda_)\n",
    "    predicted = predict(theta, X_expanded)\n",
    "    accuracy = np.mean(predicted == y.flatten()) * 100\n",
    "    print(f'Accuracy with regularization: {accuracy:.2f}%')\n",
    "    return predicted, theta, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b5ba0",
   "metadata": {},
   "source": [
    "#### Regularization: Decide the polynomial feature, number of iterations, lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ffa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power, num_iters, alpha, lambda_ = 20, 20000, 0.6, 1\n",
    "predicted, theta, costs = logistic_regression_with_reg(X, y, power=power, alpha=alpha, num_iters=num_iters, lambda_=lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2f196",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe accuracy is \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.2f}\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39msum(\u001b[43mpredicted\u001b[49m \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'The accuracy is {.2f}%'.format(np.sum(predicted == y.flatten()) / len(y) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d635b",
   "metadata": {},
   "source": [
    "#### Regularization: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.linspace(np.min(X[:, 0]), np.max(X[:, 0]), 50)\n",
    "v = np.linspace(np.min(X[:, 1]), np.max(X[:, 1]), 50)\n",
    "\n",
    "z = np.zeros((len(u), len(v)))\n",
    "\n",
    "for i in range(len(u)):\n",
    "    for j in range(len(v)):\n",
    "        features = expand_feature(np.array([u[i]]).reshape(1, -1), np.array([v[j]]).reshape(1, -1), power=power)\n",
    "        z[i, j] = np.dot(features, theta)\n",
    "z = z.T\n",
    "\n",
    "plt.contour(u,v,z, [0, 0.01], cmap = 'Reds')\n",
    "sns.scatterplot(x = X[:, 0], y = X[:, 1], hue = y.flatten())\n",
    "plt.title('Logistic Regression with Regularization Decision Boundary')\n",
    "plt.xlabel('Feature 1 aka X')\n",
    "plt.ylabel('Feature 2 aka Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e51b1",
   "metadata": {},
   "source": [
    "Play with different hyper parameters to observe the impact on accuracy and precision and model type(over|under-fitted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
