{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f61f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3145b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f0436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the positive and negative classes\n",
    "positive_class = np.array([(-2, 3), (0, 1), (2, -1)])   # consider the class label as +1\n",
    "negative_class = np.array([(-2, 1), (0, -1), (2, -3)])   # consider the class label as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7e19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all points as data\n",
    "# data\n",
    "X = np.vstack((positive_class, negative_class))\n",
    "# labels\n",
    "y = np.hstack((np.ones(np.shape(positive_class)[0], dtype = np.int64), np.ones(np.shape(negative_class)[0], dtype = np.int64) * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a56fb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(theta, theta0, T):\n",
    "    plt.scatter(positive_class[:, 0], positive_class[:, 1], marker='o', color='blue', label='Positive Class (+1)')\n",
    "    plt.scatter(negative_class[:, 0], negative_class[:, 1], marker='*', color='red', label='Negative Class (+1)')\n",
    "    x_vals = np.linspace(np.min(positive_class[:, 0]), np.max(positive_class[:, 0]), 2)\n",
    "    try:\n",
    "        y_vals = -(theta[0] * x_vals + theta0) / theta[1]\n",
    "        plt.plot(x_vals, y_vals, color='green', label='Decision Iteration {T}.')\n",
    "    except ZeroDivisionError:\n",
    "        x_vals = -theta0 / theta[0]\n",
    "        plt.axvline(x=x_vals, color='green', label='Decision Iteartion {T}.')\n",
    "    \n",
    "    plt.xlim(-3, 3)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(f\"Perceptron Linear classifier at iteration {T}.\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761174c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Algorithm\n",
    "def perceptron(X, y, steps=100):    # steps::epoch. Maximum mistakes should be equal to T, which is (R/gamma)^2 but it can be only be found after theta is found, which makes here a deadlock.\n",
    "    # Initialize weights and bias\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    theta0 = 0\n",
    "    \n",
    "    for T in range(steps):\n",
    "        for i in range(X.shape[0]):\n",
    "            if y[i] * np.sign(np.dot(X[i], theta) + theta0) <= 0:\n",
    "                theta += y[i] * X[i]\n",
    "                theta0 += y[i]\n",
    "                break   # prevents oscillations between corrections. Better convergence properties for linearly separable data aligns with the formal perceptron algorithm.\n",
    "        # Plot after each iterations\n",
    "        plt.pause(0.5)\n",
    "        plot_decision_boundary(theta, theta0, T+1)\n",
    "    return theta, theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_final, theta0_final = perceptron(X, y, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
