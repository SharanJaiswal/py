{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DON'T FORGET\n",
    "\n",
    "There is a reson why there is frequency offset M and MS & Q and QS. Because, while resampling or using asfreq functions, if we need to put the label as the starting of these periods|groups and if we use only M|Q, then last day of that bin|period is used as label. Sometimes, like in %_range() methods, LABEL='...' argument is not present. Hence we will use the MS|QS in this case. This is just used to label the period|bin.\n",
    "\n",
    "### SM is not same as MS. Same goes for SQ and QS, and other similar offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./nasdaq_goog.csv', parse_dates=['Date'], index_col=['Date'])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2020-07']['Close'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2020-07' : '2020-08'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].resample('M').mean()    # in downsamp: closed='left'(def)|'right', label='left'(def)|'right' ;;; in upsamp: convention='start'|'end' (for data point, rest will be NaN)\n",
    "# resampling makes the bins of the data where number of bins depends on the frequency of resampling. Aggregate functions on resampled data performs on each bin\n",
    "# without any aggregate function, this will give DatetimeIndexResampler Object, which is non iterable, but kind of similar to groupby object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_rng = pd.date_range(start='2020-01-01', end='2020-12-31', freq='B')    # 'B' only eliminates Weekends, NOT the occasional holidays\n",
    "print(date_rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2020-01-12', end='2020-12-31', freq='Q') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OFFSET aliases\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/timeseries.html#offset-aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.date_range(start='2020-01-12', end='2020-12-31', freq='QS'))  # observe that if label value is not present(2020-01-01) then that range wont be included\n",
    "print(pd.date_range(start='2020-01-12', end='2020-12-31', freq='SMS'))  # there is no SQ present. Because, its absurd to find the mis of any quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(date_rng[:len(df)], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df['Close'].plot()  # kind='bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.asfreq('M', method='ffill')  # if method not provided, fills with NaN. Also fill_value=<some_def_value>\n",
    "# ffill|pad & bfill|backfill    (fills the immediate value from above/below cell from the original df, not from newly generated df with new freq)\n",
    "# as freq is like a filtering mechanism, where the row of based on specific freq is filtered out. Aggregate method on it will be applied on all those filtered row and give single answer\n",
    "# during upsampling, data is attachecd to the first of the initial index value. Here, HOW='START'|'END' only works with the PeriodIndex. Not with any other datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='1/1/2020', periods=20, freq='M')   # if we dont know the end date, but we know the number of dates to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING RANDOM DATA\n",
    "rng = pd.date_range(start='1947-12-18', periods=50, freq='B')\n",
    "import numpy as np\n",
    "dum_df = pd.DataFrame(np.random.randint(1, 10, len(rng)), index=rng)\n",
    "dum_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.date_range(start='1947-11-18', periods=50, freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='1947-10-18', periods=50, freq='Q-FEB') # remember that there could also be QS-FEB\n",
    "# WE DONT HAVE LABEL OPTION AS AN ARGUMENT HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOLIDAY CALENDER for handling the extra holidays dates in date_range of 'B' frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "usb = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "usb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='7/1/2017', end='7/21/2017', freq=usb)  # it has not included the holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05', '20170105']\n",
    "pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2017-01-05 2:30:00', '2017-01-05 2:30:00 PM', 'Jan 5, 2017 14:30:00', '01/05/2017', '2017.01.05', '2017/01/05', '20170105']\n",
    "pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05', '20170105']\n",
    "pd.to_datetime(dates, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('5#1#2017', format='%d#%m#%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05', '20170105', 'abc']\n",
    "pd.to_datetime(dates, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making datetime via epoch\n",
    "t = 1501356749\n",
    "pd.to_datetime(t, unit='s') # by default, the unit is set to ns. Hence we need to override it because the epoch is no. of seconds since 01-01-1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1501356749\n",
    "pd.to_datetime([t], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1501356749\n",
    "dt = pd.to_datetime([t], unit='s')\n",
    "dt.view('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## period; period index\n",
    "\n",
    "Since it is period(range of time), hence there is no concept of QS or MS. Instead there is just Q and M and several others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Period('2016')\n",
    "y   # in o/p, A-DEC means that period is Annual, ending with December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.Period('2011-01', freq='M')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# periods can perform arithmetic operations. It also can perform the arithmetics between two periods of same frequency.\n",
    "m+13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Period('2016-01-28', freq='D')   # by default, it will put freq='D'\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d+1 # it was aware of the leap year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = pd.Period('2017-01-09 11:50:34.345')       # fro FRAC SEC, [0-3]rd digits will be considered for 3 digits with freq 'L', for [4-6]th digits freq='U', for [7-9] freq='N'\n",
    "d0+1010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Quarter with pd.Period FREQ attr is set to 'Q-DEC' by default. Qn should be appeneded with the YYYY as YYYYQn. If custom freq is given, then end of fourth quarter is shifted to that year mentioned as a first argument, and then with Qn, denotes overall that, quarter number Qn whose Q4 will be in the year YYYY, mentioned in YYYYQn. However, it is labelled by YYYYQn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.Period('2017Q1') # Q should be appended by number 1-4 (both inclusive), otherwise error will be thrown\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.Period('2017Q2')\n",
    "q+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.start_time, q.end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = pd.Period('2017Q1', freq='Q-JAN')  # shifting quarter ending time\n",
    "q2  # remeber, although its from 2016-02-01 to 2016-04-30, but it will be still labelled as (2017Q1, Q-JAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q2.start_time, q2.end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period or PeriodIndex asfreq() is little different from datetime asfreq()\n",
    "q2.asfreq('M', how='start') # changing frequency to monthly. HOW='START'|'END' will decide that, while upsampling, what label shall be present, ie if start_time or end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.asfreq('M', how='end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Period Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range('2011', '2017', freq='Q')   # by default, both the YYYY years will be taken as YYYYQ1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range(start=pd.Period('2011Q1'), end=pd.Period('2017Q3'), freq='Q')   # custom quarter range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range(start=pd.Period('2011Q1', freq='Q-FEB'), end=pd.Period('2017Q1', freq='Q-FEB'), freq='Q')\n",
    "# Observe that o/p procues range from 2010Q2 to 2016Q2. It is because, its range is 01Mar2010 to 31May2016. These two dates are then rendered by outer frequency 'Q'\n",
    "# Inner frequncy work is over before executing outer frequency. Hence, outer freq will just look these dates and form quarters as Q-DEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range(start=pd.Period('2011Q1', freq='Q-FEB'), end=pd.Period('2017Q1', freq='Q-MAY'), freq='Q-NOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range('2011Q1', '2017Q4', freq='Q-JAN')\n",
    "# pd.period_range(start=pd.Period('2011Q1', freq='Q'), end=pd.Period('2017Q1', freq='Q'), freq='Q-JAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range('2011', '2017', freq='Q-JAN')[4].end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lux = pd.period_range('2011', periods=10, freq='Q-AUG') # for Q-AUG, in 2010, label-2010Q1 is sept-nov2010, label-2010Q2 is Dec2010-Jan2011-Mar2011. Since date starts from 20110101, hence it is 2010Q2.\n",
    "lux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lux[0].start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ps = pd.Series(np.random.rand(len(lux)), index=lux)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps['2010']  # this proves that indexing here takes reference of the underlying actual datetime. NOT the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps['2011']  # since 2011Q2 ranges from 2010-2011, hence it comes in both 2010 and 2011 indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps['2011':'2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = ps.to_timestamp() # Since we are converting a range to a point of time, therefore there must be HOW='START'(def)|'END'. Also there can be FREQ='..-.....'\n",
    "pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.to_period() # freq='......' can also be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69 = pd.read_csv('./wmt.csv')\n",
    "df69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69.set_index('Line Item', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69 = df69.T   # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69.index  # it is of type object. We need to convert it to period type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69.index = pd.PeriodIndex(df69.index, freq='Q-JAN')\n",
    "df69.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69['start date'] = df69.index.map( lambda x : x.start_time)\n",
    "df69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df69['end date'] = df69.index.map( lambda x : x.end_time.date)\n",
    "df69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TZ\n",
    " Two types: Naive datetime (not aware of TZ); TZ aware datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./nasdaq_goog.csv', index_col='Date', parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting naive datetime to some timezone aware datetime\n",
    "df = df.tz_localize(tz='US/Eastern')\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import all_timezones\n",
    "all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.tz_localize(tz='Asia/Calcutta')   # once it is localized, ie converted to UTC, again it wont be converted.\n",
    "# we need to use tz_convert\n",
    "df = df.tz_convert('Asia/Calcutta') # can be None also in the brcaket\n",
    "# df.index = df.index.tz_convert('Asia/Calcutta')       # similar effect\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  normally date_range creates naive datetimeIndex\n",
    "rng = pd.date_range(start='1/1/2017', periods=10, freq='H')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(start='1/1/2017', periods=10, freq='H', tz='Asia/Calcutta')\n",
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arithmetic between two different TZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(start='2017-08-22 09:00:00', periods=10, freq='30T')\n",
    "s = pd.Series(range(10), index=rng)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = s.tz_localize(tz='Europe/Berlin')\n",
    "b.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s.tz_localize(tz='Asia/Calcutta')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b+m # it found corresponding UTC TZs and performed addition only on equal UTC time. Rest all left as NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting and Lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./nasdaq_goog.csv', parse_dates=['Date'], index_col='Date')\n",
    "df.index = df.index.date\n",
    "print(df.index)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df[['Open']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(1) # shifts data one cell down. Last cell data will be vanished, and first cell will get occupied by NaN. Shifting can be called on both DF and TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(-2)    # shifts 2 cells up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application: to check change in price\n",
    "df['Prev Day Price'] = df['Open'].shift(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Chnage in 1 day'] = df['Prev Day Price'] - df['Open']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now instead of shifting of data points, we will shift the dates\n",
    "df = df[['Open']]\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index        # its frequency is None. But it is 'B'  type frequency. So, shifting wont have idea that by what value(freq), dates need to be shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.date_range(start=df.index.min(), periods=len(df.index), freq='B')\n",
    "df.index    # index has now frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tshift(1)    # neagtive value is also supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COreys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.date(2016,7,24)    # digits are passed, without prefixed zero in the day or month part\n",
    "print(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tday = datetime.date.today()\n",
    "tday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tday.year, tday.day, tday.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( tday.isoweekday(), tday.weekday())   # iso::Monday:1 & Sunday:7      #normal::Monday:0 & Sunday:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta = datetime.timedelta(days=7) # timedelta gives a duration of time in certain units\n",
    "tdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = date <operator> timedelta\n",
    "# timedelta = date <operator> date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tday + tdelta)\n",
    "print(tday - tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday = datetime.date(2020, 7, 15)\n",
    "till_bday = bday - tday\n",
    "print(till_bday)\n",
    "print(till_bday.days)\n",
    "print(till_bday.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.time(9, 30, 45, 100000)\n",
    "print(t)\n",
    "print(t.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime(2016,7,26,12,30,45,100000)\n",
    "print(t)\n",
    "print(t.date())\n",
    "print(t.time())\n",
    "print(t.year)\n",
    "print(t.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta = datetime.timedelta(days=7)\n",
    "print(t + tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta = datetime.timedelta(hours=12)\n",
    "print(t + tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_today = datetime.datetime.today()   # returns current local datetime with no TZ info or manipulation # Naive datetime\n",
    "dt_now1 = datetime.datetime.now()   # if no TZ is provided, current TZ will be taken by default. Works like today() # Naive datetime\n",
    "# dt_now2 = datetime.datetime.now()   # if TZ is provided, gives current UTC time with TZ provided info # TZ aware datetime. # TZ aware datetime\n",
    "dt_utcnow1 = datetime.datetime.utcnow() # gives current UTC time without any TZ info. # Naive datetime\n",
    "# dt_utcnow2 = datetime.datetime.utcnow() # gives current UTC time with TZ provided info # TZ aware datetime\n",
    "print(dt_today)\n",
    "print(dt_now1)\n",
    "print(dt_utcnow1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "# python recommends using pytz and perform utc TZ aware time operations\n",
    "\n",
    "dt = datetime.datetime(2016, 7, 27, 12, 30, 45, tzinfo=pytz.UTC)\n",
    "print(dt)\n",
    "\n",
    "# useful for getting current time\n",
    "dt_now = datetime.datetime.now(tz=pytz.UTC)\n",
    "print(dt_now)\n",
    "\n",
    "# not useful. Seems muddled\n",
    "dt_utcnow = datetime.datetime.utcnow().replace(tzinfo=pytz.UTC)\n",
    "print(dt_utcnow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_now = datetime.datetime.now(tz=pytz.UTC)\n",
    "print(dt_now)\n",
    "\n",
    "dt_ind = dt_now.astimezone(pytz.timezone('Asia/Calcutta'))   # astimezone will work only with the TZ aware datetime. NOT with Naive datetime. Hence we first converted Naive to TZ aware\n",
    "print(dt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tz in pytz.all_timezones:\n",
    "    print(tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_mtn = datetime.datetime.now()    # naive datetime\n",
    "mtn_tz = pytz.timezone('US/Mountain')   # fetched TZ\n",
    "\n",
    "dt_mtn = mtn_tz.localize(dt_mtn)    # converted naive datetime to TZ aware datetime\n",
    "print(dt_mtn)   # printz TZ aware datetime\n",
    "\n",
    "# if we would have not converted to TZ aware, below would have given error\n",
    "dt_east = dt_mtn.astimezone(pytz.timezone('US/Eastern'))\n",
    "print(dt_east)\n",
    "\n",
    "# below we see how to convert the one time of one TZ to another TZ\n",
    "dt_ind = dt_east.astimezone(pytz.timezone('Asia/Calcutta'))\n",
    "print(dt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_mtn = datetime.datetime.now(tz=pytz.timezone('US/Mountain'))\n",
    "print(dt_mtn.isoformat())\n",
    "print(dt_mtn.strftime('%B %d, %Y'))\n",
    "\n",
    "\n",
    "dt_str = 'August 13, 2021'\n",
    "dt = datetime.datetime.strptime(dt_str, '%B %d, %Y')\n",
    "print(dt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6570200391abd47b22bafa3ab36aba8327b6bca09374d4d4cb5f21cfca217ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
